{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 1\n",
    "- Check if question is longer than 19 characters\n",
    "- Check if answer is longer than 50 characters\n",
    "- Replace bad characters in question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "with open(\"../scraper_viva/viva.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "\n",
    "viva_data = []\n",
    "len_answer_question = 0\n",
    "bad_chars = 0\n",
    "\n",
    "with tqdm(total=len(data), desc=\"Checking ...\") as pbar:\n",
    "    for ans in data:\n",
    "        if any(char in ans[\"question\"] for char in [\"\\n\", '\"', \"-\"]) or any(\n",
    "            char in ans[\"answer\"] for char in [\"\\n\", '\"', \"-\"]\n",
    "        ):\n",
    "            bad_chars += 1\n",
    "\n",
    "        question = (\n",
    "            ans[\"question\"].replace(\"\\n\", \" \").replace('\"', \"\").replace(\"-\", \" \").replace(\"_\", \" \")\n",
    "        )\n",
    "        answer = (\n",
    "            ans[\"answer\"].replace(\"\\n\", \" \").replace('\"', \"\").replace(\"-\", \" \").replace(\"_\", \" \")\n",
    "        )\n",
    "\n",
    "        if len(question) > 19 and len(answer) > 50:\n",
    "            viva_data.append(\n",
    "                {\n",
    "                    \"url\": ans[\"url\"],\n",
    "                    \"question\": question,\n",
    "                    \"answer\": answer,\n",
    "                    \"time\": ans[\"time\"],\n",
    "                    \"title\": ans[\"title\"],\n",
    "                }\n",
    "            )\n",
    "        else:\n",
    "            len_answer_question += 1\n",
    "\n",
    "        pbar.set_postfix({\"len_answer_question\": len_answer_question, \"bad_chars\": bad_chars})\n",
    "\n",
    "        pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"viva-data.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(viva_data, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 2\n",
    "- Checking grammar mistakes in question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "import language_tool_python\n",
    "import json\n",
    "\n",
    "tool = language_tool_python.LanguageTool(\"sl\")\n",
    "new_data_viva = []\n",
    "bad_sentence = 0\n",
    "bad_sentence_data = []\n",
    "\n",
    "with open(\"viva-data.json\") as f:\n",
    "    data = json.load(f)\n",
    "\n",
    "with tqdm(total=len(data), desc=\"Checking profanity\") as pbar:\n",
    "    for ans in data:\n",
    "        question = ans[\"question\"]\n",
    "        answer = ans[\"answer\"]\n",
    "        check_sentence_question = tool.check(question)\n",
    "        check_sentence_answer = tool.check(answer)\n",
    "\n",
    "        if len(check_sentence_question) <= 20 and len(check_sentence_answer) <= 20:\n",
    "            new_data_viva.append(ans)\n",
    "        else:\n",
    "            bad_sentence_data.append(\n",
    "                {\n",
    "                    \"url\": ans[\"url\"],\n",
    "                    \"question_err\": check_sentence_question,\n",
    "                    \"answer_err\": check_sentence_answer,\n",
    "                    \"question\": question,\n",
    "                    \"answer\": answer,\n",
    "                }\n",
    "            )\n",
    "            bad_sentence += 1\n",
    "\n",
    "        pbar.set_postfix({\"bad sentence\": bad_sentence})\n",
    "        pbar.update(1)\n",
    "\n",
    "tool.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bad_sentence_data = sorted(bad_sentence_data, key=lambda x: len(x[\"question_err\"]) + len(x[\"answer_err\"]), reverse=True)\n",
    "bad_sentence_data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"viva-data-grammar.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_data_viva, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check 3\n",
    "- Check if bad words are present in question and answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from translate import Translator\n",
    "from profanity_check import predict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def translate_to_slovenian_and_check_profanity(text, translator):\n",
    "    translated_text = translator.translate(text)\n",
    "    profani = predict([translated_text])[0]\n",
    "    return True if profani == 1 else False\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    new_data_not_profanity = []\n",
    "    prof_count = 0\n",
    "    translator = Translator(from_lang=\"sl\", to_lang=\"en\")\n",
    "\n",
    "    with open(\"viva-data.json\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    with tqdm(total=len(data), desc=\"Checking profanity\") as pbar:\n",
    "        for ans in data:\n",
    "            question = ans[\"question\"]\n",
    "            answer = ans[\"answer\"]\n",
    "            check_profanity_question = translate_to_slovenian_and_check_profanity(\n",
    "                question, translator\n",
    "            )\n",
    "            check_profanity_answer = translate_to_slovenian_and_check_profanity(answer, translator)\n",
    "\n",
    "            if not check_profanity_question and not check_profanity_answer:\n",
    "                new_data_not_profanity.append(ans)\n",
    "            else:\n",
    "                prof_count += 1\n",
    "\n",
    "            pbar.set_postfix({\"profanity\": prof_count})\n",
    "            pbar.update(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./final-data/iva-data-final.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(new_data_not_profanity, f, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
